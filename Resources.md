# Deep Learning and Neural Networks Resources

## Books
[Deep Learning, Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/books/deeplearning_latest_edition.pdf)

[Neural Networks - Systematic Introduction, Raul Rojas, 1996](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/books/neuron.pdf)

[Machine Learning - A Probabilistic Perspective, Kevin P. Murphy, 2012](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/books/MachineLearning-AProbabilisticPerspective.pdf)


## Articles and tutorials
[Learning Representations by Back-propagating Errors, D. Rumelhart, G. Hinton, R. Williams,Nature, 1986](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Learning_representations_by_backpropagating_errors_Rummelhart_Hinton_Williams_1986.pdf)

[Multilayer Feedforward Networks are Universal Approximators, Kurt Hornik, Maxwell Stinchcombe, Halber White, 1989](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/MultilayerFeedforwardNetworksAreUniversalApproximatorsHornik89.pdf)

[Multilayer Feedforward Networks With a Nonpolynomial Activation Function Can Approximate Any Function, M. Leshno, V. Y. Lin, A. Pinkus, S. Schocken, 1993](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/MultilayerFeedforwardNetworksWithNonpolynomialActivationFunctionCanApproximateAnyFunctionLeshno1993.pdf)

[ImageNet Classification with Deep Convolutional Neural Networks, Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton, NIPS, 2012](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf)

[Transforming Auto-encoders, G. Hinton, A. Krizhevsky, S.D. Wang, 2011](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/TransformingAutoencodersHinton.pdf)

[On the Importance of Initialization and Momentum in Deep Learning, Ilya Sutskever, James Martens, George Dahl, Geoffrey Hinton, 2013](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/OnTheImportanceOfInitializationAndMomentumInDeepLearningSutskever13.pdf)

[Distilling the Knowledge in a Neural Network, G. Hinton et al, 2015](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Distilling_the_Knowledge_in_a_Neural_Network_Hinton_2015.pdf)

[The Forward-Forward Algorithm: Some Preliminary Investigations, Geoffrey Hinton, 2022](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/The_Forward-Forward_Algorithm-Some_Preliminary_Investigations_Hinton_2022.pdf)

[Neural Networks and Deep Learning, Michael Nielsen, 2018](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/NeuralNetworksAndDeepLearningNielsen.pdf)

[Deep Learning: Methods and Applications, Li Deng, Dong Yu, 2014](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/DeepLearning-NowPublishing-Vol7-SIG-039.pdf)

[Universal Approximation of an Unknown Mapping and Its Derivatives Using Multilayer Feedforward Networks, Kurt Hornik, Maxwell Stinchcombe, Halbert White, 1990](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/UniversalApproximationOfUnknownMappingHrnik90.pdf)

[The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, J. Frankle, M. Carbin MIT CSAIL 2019](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/TheLotteryTicketHypothesisFindingSparseTrainableNeuralNetworksFrankle2017.pdf)

[A Theory of Transfer Learning with Applications of Active Learning, Liu Yang, Steve Hanneke, Jaime Carbonell, Carnegie Mellon University, 2013](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/TheoryOfTransferLearningWithApplicationsToActiveLearningCMUYang.pdf)

[Learning with Local and Global Consistency, D. Zhou, O. Bousquet, T. Lal, J. Weston, B. Scholkopf, 2003](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/NIPS-2003-learning-with-local-and-global-consistency-Paper.pdf)

[Bagging, Boosting and Ensemble Methods, Peter Buehlmann, ETH Zurich, 2010](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Bagging_Boosting_and_Ensemble_Methods_Buhlmann_2010.pdf)

[Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition, Dominik Scherer, Andreas Mueller, Sven Behnke, 2010](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/EvalutationOfPoolingOperationsInConvolutionalArchitecturesForObjectRecognition.pdf)

[Learning Deep Architectures for AI, Yoshua Bengio, 2009](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Learning_Deep_Architectures_for_AI_Y_Bengio_2009.pdf)

[Learning both Weights and Connections for Efficient Neural Networks, Song Han et al, Stanford U, 2015](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/learning-both-weights-and-connections-for-efficient-neural-network-Han-Pool-Tran-Dally-2015.pdf)

[Boosting Algorithms: Regularization, Prediction and Model Fitting, Peter Buehlmann, Torsten Hothorn, 2008](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/BoostingAlgorithmsRegularizationPredictionAndModelFittingBuehlman2007.pdf)

[Least Angle Regression, Bradley Efron, Trevor Hastie, Iain Johnstone, Robert Tibshirani, 2004](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/LeastAngleRegressionEffron2004.pdf)

[Regression Shrinkage and Selection via the Lasso, Robert Tibshirani, 1996](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/RegressionShrinkageAndSelectionViaTheLassoTibshirani1996.pdf)

[The Modern Mathematics of Deep Learning, J. Berner et al, 2021](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/ModernMathematicsOfDeepLearning2021.pdf)

[Introduction To Metric Fixed Point Theory, M.A. Khamsi, 2002](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/IntroductionToMetricFIxedPointTheoryKhamsi.pdf)

[A Global Geometric Framework for Nonlinear Dimensionality Reduction, J. Tenenbaum, et al, 2000](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/GlobalGeometricFrameworkForNonlinearDimensionalityReductionTenenbaum2000.pdf)

[Online Learning and Stochastic Approximations, Leon Bottou, AT&T Labs, 1998](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/OnlineAlgorithmsAndStochasticApproximationsBottou1998.pdf)

[A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting, Yoav Freund, Robert E Schapire, 1996](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/decision-theoretic_generalization_of_online_learning_and_app_to_Boosting_Freund1996.pdf)

[Improving Generalization With Active Learning, David Cohn, Les Atlas, Richard Landner, 1994](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Cohn1994_ImprovingGeneralizationWithActiveLearning.pdf)

[Pruning Convolutional Neural Networks for Resource Efficient Inference, P. Molchanov, S. Tyree, T. Karras, T. Aila, J. Kautz, NVIDIA, 2017](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/PruningCNNForResourceEfficientInferenceMolchanov2017.pdf)

[What is The State of Neural Network Pruning? D. Blalock, J. Ortiz, J. Frankle, J. Guttag, 2020](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/WhatIsTheStateOfNeuralNetworkPruningBlalock2020.pdf)

[Deep Ensembles: A Loss Landascape Perspective, S. Fort et al, Google Research, 2020](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Deep_Ensembles-A_Loss_Landscape_Perspective_Fort_GoogleBrain_2020.pdf)

[You Only Look Once: Unified, Real-Time Object Detection, J. Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi, 2016](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/YOLO-UnifiedRealTimeObjectDetection.pdf)

[Employing EM in Pool-Based Active Learning for Text Classification, A. McCallum, K. Nigam, 1998](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/EmployingEMinPoolBasedActiveLearningForTextClassificationMcCallum98.pdf)

[Approximation Capabilities of Multilayer Feedforward Networks, Kurt Hornik, 1991](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/ApproximationCapabilitiesOfMultilayerFeedforwardNetworksHornik1991.pdf)

[Approximation by Superpositions of a Sigmoidal Function, G. Cybenko, 1989](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/ApproximationBySuperpositionsOfSigmoidalFunctionCybenko1989.pdf)

[Fast R-CNN, Ross Girshick, Microsoft Research, 2015](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Fast_R-CNN.pdf)

[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, S. Ren, K. He, Ross Girshick, Jian Sun, 2016](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks.pdf)

[Feature Extraction using Convolution Neural Networks (CNN) and Deep Learning, M. Jogin, et al](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Feature_Extraction_Using_CNN_and_DeepLearning.pdf)

[Feature Representation In Convolutional Neural Networks, Ben Athiwaratkun et al, Cornell U, 2011](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Feature_Representation_in_CNN.pdf)

[Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation, Tech Report, UC Berkeley, 2014](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/RCNN_RichFeatureHierarchiesForAccurateObjectDetection.pdf)

[Pyramid Methods in Image Processing, E.H. Adelson, et al,  RCA, 1984](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/PyramidMethodsForImageProcessingRCA84.pdf)

[Learning Sparse Neural Networks Through L_0 Regularization, Christos Louizos, Max Welling, Diederik P. Kingma, 2018](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Learning_Sparse_Neural_Networks_Through_L0_Regularization_ICLR_2018.pdf)

[Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, Gal et al, Cambridge, 2016](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Dropout_as_a_Bayesian_Approximation-Representing_Model_Uncertainty_in_Deep_Learning_Gal_2016.pdf)

[Bayesian Learning for Neural Networks: Algorithmic Survey, Martin Margis, Alexandros Iosifidis, 2023](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/Bayesian_Learning_for_Neural_Networks-an_algorithmic_survey_2023.pdf)

[Bayesian Methods for Neural Networks, Joao de Freitas, Cambridge U., 2000, PhD thesis](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/books/Bayesian_Methods_For_Neural_Networks_Freitas_PhD_thesis_CambdridgeU_2000.pdf)

[A Comprehensive guide to Bayesian Convolutional Neural Network with Variational Inference, Kumar Shridhar et al, 2019](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/A_Comprehensive_guide_to_Bayesian_Convolutional_Neural_Network_with_Variational_Inference_Shridhar_2019.pdf)

[What Every Computer Scientist Should Know About Floating-Point Arithmetic, D. Goldberg, 1991](https://github.com/dimitarpg13/deep_learning_and_neural_networks/blob/main/literature/articles/WhatEveryScientistShouldKnowAboutFloatingPointNumbersGoldberg1991.pdf)

## medium
[Ensemble Learning: Bagging and Boosting with Jonas Dieckmann](https://towardsdatascience.com/ensemble-learning-bagging-and-boosting-23f9336d3cb0)

[Pruning Neural Networks, Rohit Bandaru, 2020](https://towardsdatascience.com/pruning-neural-networks-1bb3ab5791f9)

[Nesterov Momentum Explained with examples in TensorFlow and PyTorch with Giorgio Martinez, 2022](https://medium.com/@giorgio.martinez1926/nesterov-momentum-explained-with-examples-in-tensorflow-and-pytorch-4673dbf21998)

[An Overview for Model Compression Techniques for Deep Learning in Space with Hannah Peterson](https://medium.com/gsi-technology/an-overview-of-model-compression-techniques-for-deep-learning-in-space-3fd8d4ce84e5)

[Gentle Introduction to Bayesian Deep Learning with François Porcher](https://pub.aimind.so/a-gentle-introduction-to-bayesian-deep-learning-d298c7243fd6)

[Why Deep Learning Ensembles Outperform Bayesian Neural Networks with Devansh](https://medium.com/swlh/why-deep-learning-ensembles-outperform-bayesian-neural-networks-dba2cd34da24)

[Bayesian Neural Network Series Post 1: Need for Bayesian Neural Networks with Kumar Shridhar](https://medium.com/neuralspace/bayesian-neural-network-series-post-1-need-for-bayesian-networks-e209e66b70b2)

[Bayesian Neural Network Series Post 2: Background Knowledge with Kumar Shridhar](https://medium.com/neuralspace/bayesian-neural-network-series-post-2-background-knowledge-fdec6ac62d43)

[Spectral Graph Convolutions with Jose Luis Castro Garica](https://medium.com/@jlcastrog99/spectral-graph-convolutions-c7241af4d8e2)

[TS2Vec review: Towards universal time series representation learning with hierarchical contrasting with Alexander Li](https://medium.com/@findalexli/ts2vec-review-towards-universial-time-series-representation-learning-with-hierarchical-contra-c50dd789e85c)



## Relevant Repos

* [Intro to Deep Learning (Tebs Labs fork)](https://github.com/dimitarpg13/intro-to-deep-learning/tree/master) 

